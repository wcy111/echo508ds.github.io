[{"title":"迎着风","url":"/2022/11/19/迎着风/","content":"\n<!-- more -->\n\n{% meting \"500665328\" \"netease\" \"song\" \"autoplay\"%}\n\n杭州时间2021年4月5日, 和朋友捣鼓了好一阵子终于建成了这个博客。 5月22日，在杭电刚完成毕设的我，怀揣着复杂的心情在这个博客里写下了第一篇感悟《终点与意义》。\n\n安娜保时间2022年11月19日，离master毕业剩下不到1个月多月的时间。忙的焦头烂额，神秘力量驱使我在停更6个月的博客里记录下此时此刻。\n\n好了我累了，不想记录了，空了再说。\n\n\n\n\n\n\n\n\n\n","tags":["Life","Meaning"],"categories":["Life","Record"]},{"title":"阅读分享","url":"/2022/06/01/一些记录/","content":"\n<!-- more -->\n\n{% meting \"4878593\" \"netease\" \"song\" %}\n\n以前喜欢陆小凤喜欢楚留香, 再后来又是傅红雪, 但是越长大越觉得小鱼儿才是古龙笔下最有意思的一个人物。\n\n因为真的很喜欢这个故事, 喜欢这个故事中的人物, 以及他们的恩爱情仇。 所以在这里分享一些阅读过程中, 比较有感触的片段吧。\n\n>小鱼儿道:\"笑伯伯，你莫要生气好么？\"\n>\n>哈哈儿道:\"生什么气？\"\n>\n>小鱼儿道：”我实在想笑的，只是......我一笑全身都疼，实在笑不出。“\n>\n>哈哈儿大笑道：”傻孩子，告诉你，笑伯伯我在笑的时候，身上有时也在疼的,但我身上愈疼，就笑的愈凶。“\n>\n>哈哈儿大笑道：”傻孩子，告诉你，笑伯伯我在笑的时候，身上有时也在疼的，但我身上愈疼，就笑的愈凶。“\n>\n>小鱼儿炸了眨眼睛，道：”为什么？“\n>\n>哈哈儿道：”你可知道，笑不但是灵药，也是武器......最好的武器，我简直从未发现过一样比笑更好的武器。“\n>\n>\n>\n>---- 8章《近墨者黑》\n\n\n\n>铁心男骑在马上，小鱼儿拉着马， 铁心男没有说话，小鱼儿也没有说话，那小白马自然更不会说话了。\n>\n>夜，很静，很冷，回头望去，仍可望见那无际的大草原，静静地沐浴在星光下，草浪起伏如海浪。他们终于走出了草原，这平静但又雄起壮丽，单调却又变化迷人的大草原，已在小鱼儿心中留下永生不能磨灭的印象。 \n>\n>---- 14章《倩女现形》\n>\n>----\n\n---\n\n\n>她痴痴地怔在那里，似已永远不能动了，春风仍然吹得很暖，但她的心却开始一寸寸结成冰。\n>\n>她仍然闭着眼，不敢睁开，她怕那令人迷乱狂醉的美梦在她眼前粉碎，但是她长长的睫毛上，已出现了一滴晶莹的眼泪。\n>\n>夜已深了，谁也不知道夜是何时来的。海红珠更不知道，她几乎什么都不知道了。\n>\n>灯笼已亮起，人群已聚拢，海四爹已开始用他那独特的豪爽笑声，在大声说着一些吸引人群的话。\n>\n>无论她有了多大的改变，但生活却必须继续。于是，海红珠又跃上了绳索。\n>\n>她麻木地在绳索上走着，人群的欢笑声，鼓掌声，都似乎已距离她十分遥远，十分遥远......只因她的心，已飞驰到远方。\n>\n>那地方永远春光明媚，在那地方，人们永远能和自己心爱的人厮守在一起，永远不必装出卑贱的笑脸。\n>\n>---- 41章《流浪江湖》\n\n---\n>苏樱悠悠道：\"你生怕我以后会压倒你，更怕自己以后会爱我爱得发疯，所以就故意做出这种样子来保护自己，只因为你拼命想叫别人认为你是个无情无义的人，但你若真的无情无义，也就不会这么样做了\"\n>\n>小鱼儿跳起来道：”放屁放屁，简直是放屁。“\n>\n>苏樱道：”一个人若被人说破心事，总难免会生气的，你虽骂我，我也不怪你。“\n>\n>小鱼儿瞪眼瞧着她，又瞧了半晌，喃喃道：”老天呀，老天呀！你怎么让我遇见这样的女人。“他嘴里说着话，忽然一个筋斗跳入水里，打着自己的头道：”完蛋了，完蛋了，我简直完蛋了，一个男人若遇见如此自作多情的女人，他只有剃光了头做和尚去。“\n>\n>--- 98章 《生死两难》\n---\n\n>小鱼儿跷起了脚，大笑道：”我打的主意，就是要别人都猜不透我。一个人做的事若都已在别人意料之中，他活着岂非也和死了差不多？“\n>\n>--- 98章 《生死两难》\n\n---\n\n>她脸上虽然装出很生气的样子，其实心里也不知有多么高兴，因为她知道她的手已渐渐开始能摸到小鱼儿的心了。\n>\n>//\n>\n>苏樱凄然一笑，道：”这也许是因为我太想得到小鱼儿了，所以才不愿让他以后恨我，我要让他自己选择，他喜欢的若是你，我就算杀了你，也没有用的。“\n>\n>--- 100章 《双骄再聚》\n\n---\n\n>小鱼儿摇着头道: ”花无缺呀花无缺，你的毛病就是太信任女人了！......“\n>\n>苏樱幽幽叹息了一声，喃喃道：”小鱼儿呀小鱼儿，你的毛病就是太不信任女人了。“\n>\n>她忽然端起桌上的另一杯酒，一口喝了下去。\n>\n>---- 第124章 《天地茫茫》\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n>\n","tags":["Life","Reading"],"categories":["Life","Record"]},{"title":"随笔","url":"/2022/05/24/随笔/","content":"\n{% meting \"28160039\" \"netease\" \"song\" %}\n\n<!-- more -->\n\n闲来没事翻开手机的相簿，发现一段文字的截图，忘了是哪儿截的，也完全没了印象。也许是当时没能产生足够的共鸣或者是有更多的理解。但是无论如何，在现在这个时间节点，我想在这里截取一些记录下来。\n\n> 现实的发展往往与人的意识相反，\n>\n> 当你已经开始想象成功的自己，那么应该意识到，成功正在远离你。\n>\n> 积极往往是去悲观地思考，然后不断发现现实总是比预期的慷慨。\n>\n> 物极必反，如果想让事物走向极致，就得用人的意识去作对冲，时刻杜绝反方向的发展。\n>\n> 想要变得自信，必须先学会如何在自我怀疑中证明自己。\n>\n> 要想不陷入自卑，必须先学会避免良好的自我感觉。\n>\n> 觉得双方关系已经亲密无间了，往往不经意间做出放肆的举动。\n>\n> 总是心怀敬畏，才可能跌跌撞撞走到最后。\n>\n> **太想得到一件东西，有时得先摆脱渴望得到的念头。**\n>\n> **直到你可以承受无法得到的结果，直到这种渴望不再扭曲你的行为。**\n\n","tags":["Life","Meaning"],"categories":["Life","Record"]},{"title":"Proximal Gradient Methods","url":"/2022/02/16/Proximal-Gradient-Methods/","content":"\nBetter method to deal with non-smooth optimization problems.\n\n<!-- more -->\n\n{% asset_img image.png %}\n\n## Motivation\n\ndifference betwwen subgradient and \n\n## Prerequisites\n\n### Euclidean projection on a set\n\nAn Euclidean projection of a point $x_{0} \\in \\mathbf{R}^{n}$ on a set $\\mathbf{S} \\subseteq \\mathbf{R}^{n}$ is a point that achieves the smallest Euclidean distance from $x_{0}$ to the set. That is, it is any solution to the optimization problem\n$$\n\\min _{x}\\left\\|x-x_{0}\\right\\|_{2}: x \\in \\mathbf{S} .\n$$\nWhen the set $\\mathbf{S}$ is convex, there is a unique solution to the above problem. In particular, the projection on an affine subspace is unique.\n\n### Smooth Approximation\n\n**Definition**. A **convex function** $f$ is called **$(\\alpha, \\beta)$-smoothable**, if for any **$\\mu>0$,** there exists a **convex function** $f_{\\mu}$, such that\n\n- $f_{\\mu}(\\boldsymbol{x}) \\leq f(\\boldsymbol{x}) \\leq f_{\\mu}(\\boldsymbol{x})+\\beta \\mu, \\quad \\forall \\boldsymbol{x}$\n- $f_{\\mu}$ is $\\frac{\\alpha}{\\mu}$-smooth, with gradient:\n$\\left\\|\\nabla f_{\\mu}(\\boldsymbol{x})-\\nabla f_{\\mu}\\left(\\boldsymbol{x}^{\\prime}\\right)\\right\\|_{2} \\leq \\frac{\\alpha}{\\mu|}\\left\\|\\boldsymbol{x}-\\boldsymbol{x}^{\\prime}\\right\\|_{2}, \\quad \\forall \\boldsymbol{x}, \\boldsymbol{x}^{\\prime} \\in \\mathbb{R}^{n}$\n\n**Note**:\n\n$f_{\\mu}$ is called a $\\frac{1}{\\mu}$ smooth approximation of with parameters $(\\alpha, \\beta)$ \n\n$\\mu:$ tradeoff between approximation accuracy $\\epsilon$ and smoothness\n\n#### Example\n\nSmooth approximation to:\n\n- l1 norm \n- l2 norm\n- max function\n\n### Basic composition rules\n\n####  Addition\n\n#### Affine Transformation\n\n### Smoothing via the Moreau Envelope\n\n#### **Definition**.\nThe Moreau envelope of a convex function $f$ with parameter $\\mu>0$ is defined as\n$$\nM_{\\mu f}(\\boldsymbol{x}):=\\inf _{\\boldsymbol{z}}\\left\\{f(\\boldsymbol{z})+\\frac{1}{2 \\mu}\\|\\boldsymbol{x}-\\boldsymbol{z}\\|_{2}^{2}\\right\\}\n$$\n\n- $M_{\\mu f}$ is a smoothed approximation of $f$;\n- **Minimizer of $f=$ minimizers of $M_{\\mu f}$.**\n\n#### **Properties**\n\n- $M_{\\mu f}$ is convex;\n- $M_{\\mu f}$ is $\\frac{1}{\\mu}$-smooth;\n- If $f$ is $L-$ Lipschitz, then $M_{\\mu f}$ is a $\\frac{1}{\\mu}$-smooth approximation of $f$ with parameters $\\left(1, L^{2} / 2\\right)$.\n\n#### Proximal Operator &  Connections\n\nDefinition. The proximal operator for a convex function $f$ is defined as\n$$\n\\operatorname{prox}_{\\mu f}(\\boldsymbol{x})=\\arg \\inf _{\\boldsymbol{z}}\\left(f(\\boldsymbol{z})+\\frac{1}{2 \\mu}\\|\\boldsymbol{z}-\\boldsymbol{x}\\|_{2}^{2}\\right)\n$$\n\n\n$$\nM_{\\mu f}(\\boldsymbol{x})=f(\\operatorname{prox}_{\\mu f}(\\boldsymbol{x}))+\\frac{1}{2 \\mu}\\|\\boldsymbol{x}-\\operatorname{prox}_{\\mu f}(\\boldsymbol{x})\\|_{2}^{2}\n$$\n\n\n\n\n**Example1**\n\nL1 norm\n\n**Example2** \n\nNuclear Norm\n\n**Example3**\n\nIndicator Function\n\n#### Non-exapansiveness of Proximal Operators\n\n?\n\n## Proximal operator of L0 norm\n\n**Theorem 6.6** (prox of separable functions). Suppose that $f: \\mathbb{E}_{1} \\times \\mathbb{E}_{2} \\times \\cdots \\times$ $\\mathbb{E}_{m} \\rightarrow(-\\infty, \\infty]$ is given by\n$f\\left(\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots, \\mathbf{x}_{m}\\right)=\\sum_{i=1}^{m} f_{i}\\left(\\mathbf{x}_{i}\\right)$ for any $\\mathbf{x}_{i} \\in \\mathbb{E}_{i}, \\quad i=1,2, \\ldots, m .$\nThen for any $\\mathbf{x}_{1} \\in \\mathbb{E}_{1}, \\mathbf{x}_{2} \\in \\mathbb{E}_{2}, \\ldots, \\mathbf{x}_{m} \\in \\mathbb{E}_{m}$,\n$$\n\\operatorname{prox}_{f}\\left(\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots, \\mathbf{x}_{m}\\right)=\\operatorname{prox}_{f_{1}}\\left(\\mathbf{x}_{1}\\right) \\times \\operatorname{prox}_{f_{2}}\\left(\\mathbf{x}_{2}\\right) \\times \\cdots \\times \\operatorname{prox}_{f_{m}}\\left(\\mathbf{x}_{m}\\right)\n$$\n\n\n### Gradient of Moreau envelope\n\n**Theorem**[Gradient of Moreau envelope]:\n\nThe Moreau envelope $M_{\\mu f}(\\boldsymbol{x})=f\\left(\\operatorname{prox}_{\\mu f}(\\boldsymbol{x})\\right)+\\frac{1}{2 \\mu}\\left\\|\\boldsymbol{x}-\\operatorname{prox}_{\\mu f}(\\boldsymbol{x})\\right\\|_{2}^{2}$ is continuously differentiable with gradient\n$$\n\\nabla M_{\\mu f}(\\boldsymbol{x})=\\frac{1}{\\mu}\\left(\\boldsymbol{x}-\\operatorname{prox}_{\\mu f}(\\boldsymbol{x})\\right)\n$$\n- Proximal operator is a gradient step for minimizing $M_{\\mu f}$ :\n\n$$\n\\operatorname{prox}_{\\mu f}(\\boldsymbol{x})=\\boldsymbol{x}-\\mu \\cdot \\nabla M_{\\mu f}(\\boldsymbol{x}) \\text {. }\n$$\n\n\n\n## Reference\n\n[Ref1](https://archive.siam.org/books/mo25/mo25_ch6.pdf)\n\n[Euclidean projection on a set](https://inst.eecs.berkeley.edu/~ee127/sp21/livebook/def_proj_general.html)\n","tags":["Optimization","Math","Non-smooth optimization","Proximal Gradient Methods"],"categories":["Math","Optimization","Non-smooth optimization"]},{"title":"Lipschitz Continuity basics","url":"/2022/02/15/Lipschitz-Continuity-basics/","content":"\n关于李普希兹(Lipschitz)的一些基础知识\n\n<!-- more -->\n\n{% asset_img image.png %}\n\n# Lipschitz continuous \n\n## Definition \n\n$f(\\cdot)$ is Lipschitz continuous **over** $\\boldsymbol{X}$ if $\\exists L<\\infty$, such that\n$$\n\\|f(\\boldsymbol{y})-f(\\boldsymbol{x})\\|_{\\boldsymbol{Y}} \\leq L(\\boldsymbol{x})\\|\\boldsymbol{y}-\\boldsymbol{x}\\|_{\\boldsymbol{X}}, \\forall \\boldsymbol{x}, \\boldsymbol{y} \\in \\boldsymbol{X}\n$$\nwhere \n$$\n\\mathrm{f}: \\boldsymbol{X} \\mapsto \\boldsymbol{Y} \\text { with } \\boldsymbol{X} \\text { and } \\boldsymbol{Y} \\text { being open sets; }\n$$\n$$\n\\|\\cdot\\|_{X} \\text { and }\\|\\cdot\\|_{Y} \\text { are norms on } X \\text { and } Y \\text {, respectively }\n$$\n\n## Property\n\nLet $f$ and $g$ be Lipschitz continuous functions with **best** Lipschitz constants $L_{f}$ and $L_{g}$, respectively.\n$$\n\\begin{array}{|c|c|c|}\n\\hline h(\\boldsymbol{x}) & L_{h} & \\\\\n\\hline \\hline \\alpha f(\\boldsymbol{x})+\\beta & |\\alpha| L_{f} & \\text { scale } \\backslash \\text { shift } \\\\\n\\hline f\\left(\\boldsymbol{x}-\\boldsymbol{x}_{0}\\right) & L_{f} & \\text { translate } \\\\\n\\hline f(\\boldsymbol{x})+g(\\boldsymbol{x}) & \\leq L_{f}+L_{g} & \\text { add } \\\\\n\\hline f(g(\\boldsymbol{x})) & \\leq L_{f} L_{g} & \\text { compose } \\\\\n\\hline \\boldsymbol{A} \\boldsymbol{x}+\\boldsymbol{b} & \\|\\boldsymbol{A}\\| & \\text { affine (for same norm on } \\left.\\mathbb{F}^{M} \\text { and } \\mathbb{F}^{N}\\right) \\\\\n\\hline f(\\boldsymbol{x}) g(\\boldsymbol{x}) & ? & \\text { multiply } \\\\\n\\hline\n\\end{array}\n$$\n\n### Example\n\nThe function $f(\\boldsymbol{x})=\\|\\boldsymbol{x}\\|_{1}$ is not continuously differentiable, but Lipschitz continuous\n\n---\n\n$\\ell^{1}$-norm: $f(\\boldsymbol{x})=\\|\\boldsymbol{x}\\|_{1}$\n$$\n|f(\\boldsymbol{x})-f(\\boldsymbol{y})| \\leq\\|\\boldsymbol{x}-\\boldsymbol{y}\\|_{1} \\leq \\sqrt{n}\\|\\boldsymbol{x}-\\boldsymbol{y}\\|_{2}\n$$\n\n## Smooth Functions\n\n### Definition\n\nA differentiable function $f(x)$ is called **smooth** iff it has a **Lipschitz continuous gradient**, i.e. iff $L<+\\infin$ such that \n$$\n\\|\\nabla f(\\boldsymbol{x})-\\nabla f(\\boldsymbol{z})\\|_{2} \\leq L\\|\\boldsymbol{x}-\\boldsymbol{z}\\|_{2}, \\quad \\forall \\boldsymbol{x}, \\boldsymbol{z} \\in \\mathbb{R}^{n}\n$$\nNote: Lipschitz continuity of $\\nabla f$ is a stronger condition than mere continuity, so any differentiable function whose gradient is Lipschitz continuous is a continuously differentiable function.\n\n\n\n## Mean value theorem I\n\nTheorem. Let $f: \\mathbb{R}^{n} \\mapsto \\mathbb{R}$ be continuously differentiable. For any fixed $\\boldsymbol{x}$ and $\\boldsymbol{y}$, we have\n$$\nf(\\boldsymbol{y})=f(\\boldsymbol{x})+\\left\\langle\\nabla f\\left(\\boldsymbol{z}\\left(t_{L}\\right)\\right), \\boldsymbol{y}-\\boldsymbol{x}\\right\\rangle\n$$\nfor some $\\boldsymbol{z}\\left(t_{L}\\right)=\\left(1-t_{L}\\right) \\cdot \\boldsymbol{x}+t_{L} \\cdot \\boldsymbol{y}$ with $t_{L} \\in(0,1)$.\n\n**PS**:  we can see by the gradient of a point such that lies in line segment of two fixed point, we can always approximate the function value of another point. \n\n\n\n\n\n","tags":["Optimization","Math","Lipschitz"],"categories":["Math","Optimization","Lipschitz"]},{"title":"Norm basic","url":"/2022/02/15/Norm-basic/","content":"\n{% meting \"1407648820\" \"netease\" \"song\" %}\n\n关于范数(Norm)的一些基础知识\n\n<!-- more -->\n\n{% asset_img image.png %}\n\n\n为了防止遗忘 + 快速检索\n# Vector Norm\n\n## Definition\n\nA vector norm is any real-valued function $\\|\\cdot\\|$ that satisfies the following properties\n\n- if $x \\neq 0$  then $\\|x\\|\\geq0$\n\n- for any $\\alpha \\in \\mathbb{R}, \\text { then }\\|\\alpha \\boldsymbol{x}\\|=|\\alpha|\\|\\boldsymbol{x}\\|$\n- triangle inequality: $\\|\\boldsymbol{x}+\\boldsymbol{y}\\| \\leq\\|\\boldsymbol{x}\\|+\\|\\boldsymbol{y}\\|$\n\nIt can be valid, $\\|\\boldsymbol{x}\\|_{p}=\\left(\\sum_{i}\\left|x_{i}\\right|^{p}\\right)^{1 / p}$, for any $p \\geq 1$\n$$\n\\begin{aligned}\n&\\|\\boldsymbol{x}\\|_{1}=\\sum_{i}\\left|x_{i}\\right| \\\\\n&\\|\\boldsymbol{x}\\|_{2}=\\sqrt{\\sum_{i} x_{i}^{2}} \\\\\n&\\|\\boldsymbol{x}\\|_{\\infty}=\\max _{i}\\left|x_{i}\\right| .\n\\end{aligned}\n$$\n\n##  Property\n\n- Larger p results in smaller norm: $\\|x\\|_{\\infty}\\leq\\|x\\|_{2}\\leq\\|x\\|_{1}$\n\n- Some  inequalities:\n\n$$\n\\begin{aligned}\n  &\\|\\boldsymbol{x}\\|_{\\infty} \\leq\\|\\boldsymbol{x}\\|_{1} \\leq n\\|\\boldsymbol{x}\\|_{\\infty} \\\\\n  &\\|\\boldsymbol{x}\\|_{2} \\leq\\|\\boldsymbol{x}\\|_{1} \\leq \\sqrt{n}\\|\\boldsymbol{x}\\|_{2} \\\\\n  &\\|\\boldsymbol{x}\\|_{\\infty} \\leq\\|\\boldsymbol{x}\\|_{2} \\leq \\sqrt{n}\\|\\boldsymbol{x}\\|_{\\infty}\n  \\end{aligned}\n$$\n\nwhere $n$ is dimensions of the vector.\n\n## Norm for optimization problem\n\n$\\|\\boldsymbol{x}\\|_{0}$ is not a norm, optimizing (P0) is NP-hard\n$\\|\\boldsymbol{x}\\|_{1}$ is a convex surrogate of $\\|\\boldsymbol{x}\\|_{0}$, can be efficiently optimized\n\n$(P 0) \\quad \\min _{\\boldsymbol{x}}\\|\\boldsymbol{x}\\|_{0}, \\quad$ s.t. $\\quad \\boldsymbol{y}=\\boldsymbol{A} \\boldsymbol{x}$\n$(P 1) \\quad\\min _{\\boldsymbol{x}}\\|\\boldsymbol{x}\\|_{1}, \\quad$ s.t. $\\quad \\boldsymbol{y}=\\boldsymbol{A} \\boldsymbol{x}$\n\nPS: $\n\\|x\\|_{0}=\\lim _{p \\searrow 0}\\|x\\|_{p}=\\sum_{i=1}^{n} \\mathbb{1}_{x_{i} \\neq 0}, \\text { where } \\mathbb{1} . \\text { is an indicator function. }\n$\n\n\n\n# Matrix Norm\n\n## Definition\n\nDefinition (matrix operator norm): Let $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$. If $\\|\\cdot\\|_{a}$ and $\\|\\cdot\\|_{b}$ are norms on $\\mathbb{R}^{n}$ and $\\mathbb{R}^{m}$, we have\n$$\n\\|A\\|_{a \\rightarrow b}:=\\sup _{\\|\\boldsymbol{x}\\|_{a} \\leq 1}\\|A \\boldsymbol{x}\\|_{b}\n$$\nwhich satisfies the three criteria for norm, and is **submultiplicative**\n$$\n\\|\\boldsymbol{A} \\boldsymbol{B}\\|_{a \\rightarrow b} \\leq\\|\\boldsymbol{A}\\|_{a \\rightarrow b} \\cdot\\|\\boldsymbol{B}\\|_{a \\rightarrow b}\n$$\n$\\|\\boldsymbol{A}\\|_{2 \\rightarrow 2}=\\sigma_{1}(\\boldsymbol{A})$ (spectral norm, write as $\\|\\boldsymbol{A}\\|$ );\n$\\|\\boldsymbol{A}\\|_{1 \\rightarrow b}=\\max _{j=1, \\cdots, n}\\left\\|\\boldsymbol{A} \\boldsymbol{e}_{j}\\right\\|_{b}$\n$\\|\\boldsymbol{A}\\|_{a \\rightarrow \\infty}=\\max _{i=1, \\cdots, m}\\left\\|\\boldsymbol{e}_{i}^{*} \\boldsymbol{A}\\right\\|_{b}^{*}, \\quad\\|\\boldsymbol{v}\\|_{b}^{*}:=\\sup _{\\|\\boldsymbol{u}\\|_{b} \\leq 1}\\langle\\boldsymbol{u}, \\boldsymbol{v}\\rangle$\n\n## Property\n\n###  Unitary invariant matrix norms\n\nLet $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$. We say the matrix norm is **unitary invariant** if\n\n$$\n\\|\\boldsymbol{A}\\|_{\\sharp}=\\|\\boldsymbol{P} \\boldsymbol{A} \\boldsymbol{Q}\\|_{\\sharp}, \\quad \\forall \\boldsymbol{P} \\in O(m), \\boldsymbol{Q} \\in O(n) .\n$$\n\nNote In linear algebra , a complex *U* is **unitary** if its conjugate transpose **U** is also its inverse.\n\n- Spectral norm. $\\|\\boldsymbol{A}\\|_{2 \\rightarrow 2}=\\sigma_{1}(\\boldsymbol{A})=\\|\\boldsymbol{\\sigma}(\\boldsymbol{A})\\|_{\\infty}$\n- Frobenius norm.$\\|\\boldsymbol{A}\\|_{F}=\\sqrt{\\sum_{i=1}^{\\min \\{m, n\\}} \\sigma_{i}^{2}(\\boldsymbol{A})}=\\|\\boldsymbol{\\sigma}(\\boldsymbol{A})\\|_{2}$\n\n \t  - Furthermore frobenius norm can be written as:\n$$\n\\|\\boldsymbol{X}\\|_{F}=\\sqrt{\\operatorname{tr}\\left(\\boldsymbol{X}^{*} \\boldsymbol{X}\\right)}=\\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left|X_{i j}\\right|^{2}}\n$$\nSpectral norm and Frobenius norm are all Unitary invariant.\n\n## Example\n\n### Schatten p-norm\n\n Let $\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$. For any $p \\in[1,+\\infty)$, the function\n$$\n\\|\\boldsymbol{A}\\|_{S_{p}}:=\\|\\boldsymbol{\\sigma}(\\boldsymbol{A})\\|_{p}\n$$\nis a norm on $\\mathbb{R}^{m \\times n}$.\n\n#### Nuclear/trace norm\n\nConsider $p=1$, we have \n$$\n\\|\\boldsymbol{A}\\|_{*}:=\\|\\boldsymbol{A}\\|_{S_{1}}=\\sum_{i} \\sigma_{i}(\\boldsymbol{A})\n$$\n\n","tags":["Optimization","Math","Norm"],"categories":["Math","Optimization","Norm"]},{"title":"Docker","url":"/2022/02/13/Docker/","content":"\n{% asset_img docker.jpeg %}\n\n用到了docker来deploy toy project,  没怎么接触过, 浅了解一下.\n\n<!-- more -->\n\n## Motivation\n同一application放到不同的操作系统, 由于环境问题会出现各种毛病, 应用docker可以解决此类问题。\n\n## Basic idea\n\nDocker file, Docker image, Container之间的关系如下图:\n\n{% asset_img relation.png %}\n\n### Dockerfile\n\nDockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。\n\n**Docker file**  builds what's called a **docker image** which contains all the project code. (Also any installments of programs that it need)\n\n### Docker image\n\nDocker 把应用程序及其依赖, 打包在镜像(image)文件里面。只有通过这个文件, 才能生成 Docker容器。镜像文件可以看作是容器的设计蓝图。Docker 根据镜像文件生成容器的实例。同一个 镜像文件, 可以生成多个同时运行的容器实例。\n\n### Container\n\n镜像运行时的实体, 镜像(Image)和容器(Container)的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等.\n\n## Reference\n\nhttp://dockone.io/article/6051\n\nhttps://turingplanet.org/2020/11/12/docker-intro-1/\n","tags":["Machine Learning","Linux","Docker"],"categories":["Linux","Server"]},{"title":"Poem2","url":"/2021/11/12/Poem2/","content":"\n<!-- more -->\n\n{% asset_img image.png %}\n\n# O Me! O Life!\n\nby Walt Whitman - 1819-1892\n\nO Me! O life! of the questions of these recurring,\nOf the endless trains of the faithless, of cities fill’d with the foolish,\nOf myself forever reproaching myself, (for who more foolish than I, and who more faithless?)\nOf eyes that vainly crave the light, of the objects mean, of the struggle ever renew’d,\nOf the poor results of all, of the plodding and sordid crowds I see around me,\nOf the empty and useless years of the rest, with the rest me intertwined,\nThe question, O me! so sad, recurring—What good amid these, O me, O life?\n\n*Answer*.\n\nThat you are here—that life exists and identity,\nThat the powerful play goes on, and you may contribute a verse.\n\n\n\n","tags":["Life","Poem"],"categories":["Life","Poem"]},{"title":"Kernel function and Kernel trick","url":"/2021/11/09/Kernel-function and-Kernel-trick/","content":"\n## Nonlinear Feature Map\n\nTo creat a nonlinear method for regression or classifier is to transform **feature vector** via a **nonlinear feature map** \n$$\n\\Phi: \\mathbb{R}^d \\rightarrow \\mathbb{R}^{m} \\tag{1.1}\n$$\n\n\nThis way is pretty intuitive since we can just image adding some features on the original feature vector. Then apply this feature map over whole dataset get $(\\Phi(x_{i}),y_{i})\\quad \\forall i)$\n\n\n\nThus, in regression, the classifier is :\n$$\nf(\\boldsymbol{x})=\\boldsymbol{w}^{T} \\boldsymbol{\\phi}(\\boldsymbol{x})+b \\tag{1.2}\n$$\nWhere $\\boldsymbol{w}\\in \\mathbb{R}^m\\quad b \\in\\mathbb{R}$\n\n## Inner Product Kernels\n\n- Many ML algorithms depend on $\\boldsymbol{\\phi}(\\boldsymbol{x})$ only via *inner products*\n  $$\n  \\langle \\Phi(x),\\phi(x^{\\prime})\\rangle  \\tag{1.3}\n  $$\n\n- for certain $\\Phi$, the function\n  $$\n  k(u,v)=\\langle\\Phi(u),\\Phi(v)\\rangle \\tag{1.4}\n  $$\n  can be computed efficiently even m is huge or possibly infinite. k is called an inner product kernel.\n\n---\n\n### Some important kernels\n\nHomogeneous polynomia kernel\n$$\nk(u,v)=(u^Tv)^{p} \\tag{1.5}\n$$\nInhomogeneous polynomia kernel\n$$\nk(u,v)=(u^Tv+b)^{p} \\tag{1.6}\n$$\nGaussian kernel (not list here)\n\n### SPD kernels\n\n- One way to determine an inner product kernel is to construct $\\Phi$ explicitly.\n\n- Another way is to verify that k is an kernel if it satisfies the following properties\n\n  - $k:\\mathbb{R}^{d}\\times \\mathbb{R}^{d} \\rightarrow\\mathbb{R}$. k is symmetric i.e. $k(u,v)=k(v,u) \\quad\\forall u,v$\n\n  - $k$ is positive definite if:\n    $$\n    \\left[\\begin{array}{ccc}\n    k\\left(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{1}\\right) & \\cdots & k\\left(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{n}\\right) \\\\\n    \\vdots & \\ddots & \\vdots \\\\\n    k\\left(\\boldsymbol{x}_{n}, \\boldsymbol{x}_{1}\\right) & \\cdots & k\\left(\\boldsymbol{x}_{n}, \\boldsymbol{x}_{n}\\right)\n    \\end{array}\\right]\n    $$\n    is a PSD matrix for all $n\\in \\mathbb{N}$, and $x_{1}...x_{n}\\in\\mathbb{R}^{d}$\n\n- **Theorem**: k is an SPD kernel iff k is an inner product kernel.\n\n---\n\n## The Kernel Trick\n\nA machine learning algorithm is said to be **kernelizable** if it is possible to formulate the algorithm such that all training instances $x_{i}$ and any test instance $x$ occur in inner products of the form$\\langle x_{i},x{_{j}} \\rangle,\\langle x_{i},x \\rangle,\\text{or}\\langle x,x \\rangle$\n\n----\n\nSince we can suppose $\\Phi$ is a feature map associatecd to an inner product kernel k, if we apply a kernelizable algorithm to the training data  like constructing :\n$$\n\\left(\\boldsymbol{\\Phi}\\left(\\boldsymbol{x}_{1}\\right), y_{1}\\right), \\ldots,\\left(\\boldsymbol{\\Phi}\\left(\\boldsymbol{x}_{n}\\right), y_{n}\\right) \\tag{1.7}\n$$\nthen we can formulate the algorithm such that transformed feature vectors only appear via inner products $\\langle\\boldsymbol{\\Phi(x),\\Phi(x^{\\prime})}\\rangle$ with other similar transformed feature vectores.\n\n- this can be implemented by evaluating $k(u,v)=\\langle\\Phi(u),\\Phi(v)\\rangle$ which eliminates the need to ever compute $\\Phi(x)$.\n\n---\n\n## Kernel Ridge Regression\n\nRidge regression is kernelizable. use the kernel trick to extend it to a nonlinear method called ridge regression.\n\n---\n\n### Kernel ridge regresion(without offset)\n\nsince some $\\Phi$ contain a constant term, as with the inhomogeous polynomial kernel, the offset is not always needed\n\nFor the KRR(no offset), we have objective function \n$$\n\\begin{aligned}\n\\min _{w}\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-\\boldsymbol{w}^{T} \\boldsymbol{x}_{i}\\right)^{2}+\\lambda\\|\\boldsymbol{w}\\|^{2} &=\\frac{1}{n}\\|\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{w}\\|^{2}+\\lambda\\|\\boldsymbol{w}\\|^{2} \\\\\n& \\propto \\boldsymbol{w}^{T}\\left(\\boldsymbol{X}^{T} \\boldsymbol{X}+n \\lambda \\boldsymbol{I}\\right) \\boldsymbol{w}-2 \\boldsymbol{y}^{T} \\boldsymbol{X} \\boldsymbol{w}+\\boldsymbol{y}^{T} \\boldsymbol{y}\n\\end{aligned}\n \\tag{1.8}\n$$\nThe solution is\n$$\n\\widehat{\\boldsymbol{w}}=\\left(\\boldsymbol{X}^{T} \\boldsymbol{X}+n \\lambda \\boldsymbol{I}\\right)^{-1} \\boldsymbol{X}^{T} \\boldsymbol{y}\\tag{1.9}\n$$\nWhere \n$$\n\\boldsymbol{y}=\\left[\\begin{array}{c}\ny_{1} \\\\\n\\vdots \\\\\ny_{n}\n\\end{array}\\right], \n\n\\quad \\boldsymbol{X}=\\left[\\begin{array}{c}\n\\boldsymbol{x}_{1}^{T} \\\\\n\\vdots \\\\\n\\boldsymbol{x}_{n}^{T}\n\\end{array}\\right] \\in \\mathbb{R}^{n \\times d}\n$$\nNote $X^TX$ is not the gram matrix of the training data (it belongs to $\\mathbb{R^{d\\times d}}$), thus we need to further transform the solution\n\n- apply matrix inversion lemma:\n  $$\n  (\\mathbf{P}+\\mathbf{Q R S})^{-1}=\\mathbf{P}^{-1}-\\mathbf{P}^{-1} \\mathbf{Q}\\left(\\mathbf{R}^{-1}+\\mathbf{S P}^{-1} \\mathbf{Q}\\right)^{-1} \\mathbf{S P}^{-1} \\tag{1.10}\n  $$\n\nAfter simplification we get \n$$\n\\widehat{\\boldsymbol{w}}^{T}=\n\\boldsymbol{y}^{T}\\left(\\mu \\boldsymbol{I}+\\boldsymbol{X} \\boldsymbol{X}^{T}\\right)^{-1} \\boldsymbol{X} \\tag{1.11}\n$$\nNote the Gram matrix $G=XX^{T}$ appears, although the method is still not kernelized because of the matrix $X$ . However, this can be resolved by taking the inner product of $\\widehat{w}$ with a test instance $x$ . Thus introduce the notation \n$$\n\\boldsymbol{G}:=\\left[\\begin{array}{ccc}\n\\left\\langle\\boldsymbol{x}_{1}, \\boldsymbol{x}_{1}\\right\\rangle & \\cdots & \\left\\langle\\boldsymbol{x}_{1}, \\boldsymbol{x}_{n}\\right\\rangle \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\left\\langle\\boldsymbol{x}_{n}, \\boldsymbol{x}_{1}\\right\\rangle & \\cdots & \\left\\langle\\boldsymbol{x}_{n}, \\boldsymbol{x}_{n}\\right\\rangle\n\\end{array}\\right] \\quad \\boldsymbol{g}(\\boldsymbol{x}):=\\left[\\begin{array}{c}\n\\left\\langle\\boldsymbol{x}_{1}, \\boldsymbol{x}\\right\\rangle \\\\\n\\vdots \\\\\n\\left\\langle\\boldsymbol{x}_{n}, \\boldsymbol{x}\\right\\rangle\n\\end{array}\\right]\n$$\nThen we can have classifier as\n$$\n\\begin{aligned}\n\\widehat{f}(\\boldsymbol{x}) &=\\widehat{\\boldsymbol{w}}^{T} \\boldsymbol{x} \\\\\n&=\\boldsymbol{y}^{T}\\left(\\boldsymbol{X} \\boldsymbol{X}^{T}+n \\lambda \\boldsymbol{I}\\right)^{-1} \\boldsymbol{X} \\boldsymbol{x} \\\\\n&=\\boldsymbol{y}^{T}(\\boldsymbol{G}+n \\lambda \\boldsymbol{I})^{-1} \\boldsymbol{g}(\\boldsymbol{x})\n\\end{aligned} \\tag{1.12}\n$$\nThis shows that KRR w/o is kernelizable. So we apply kernek trick by simply selecting a kerenel k and replace $\\langle u,v\\rangle$ with $k(u,v)$ . After substituion, $G$ and $g(x)$ are replaced by \n$$\n\\boldsymbol{K}:=\\left[\\begin{array}{ccc}\nk\\left(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{1}\\right) & \\cdots & k\\left(\\boldsymbol{x}_{1}, \\boldsymbol{x}_{n}\\right) \\\\\n\\vdots & \\ddots & \\vdots \\\\\nk\\left(\\boldsymbol{x}_{n}, \\boldsymbol{x}_{1}\\right) & \\cdots & k\\left(\\boldsymbol{x}_{n}, \\boldsymbol{x}_{n}\\right)\n\\end{array}\\right], \\quad \\boldsymbol{k}(\\boldsymbol{x}):=\\left[\\begin{array}{c}\nk\\left(\\boldsymbol{x}_{1}, \\boldsymbol{x}\\right) \\\\\n\\vdots \\\\\nk\\left(\\boldsymbol{x}_{n}, \\boldsymbol{x}\\right)\n\\end{array}\\right]\n$$\n$K$ is called the kernel matrix. Now, the final form of the KRR(w/o) offset predictor is \n$$\n\\widehat{f}(\\boldsymbol{x})=\\boldsymbol{y}^{T}(\\boldsymbol{K}+n \\lambda \\boldsymbol{I})^{-1} \\boldsymbol{k}(\\boldsymbol{x}) \\tag{1.13}\n$$\nNote entire process is equivalent to first applying the feature map $\\Phi$ to all feature vectors, and applying ridge regression w/o in the new feature space. Because all we need is to obtain a nonlinear regression predictor and once we have selected a kernel all the calculation needed for predicting a new point is implicitly finished.\n\n#### Computational Complexity of KRR w/o\n\nThe computational complexity of KRR without offset is $O(n^3)$ which comes from having to invert an $n\\times n$ matrix.  As with regular regression, this can be accelerated using **gradient descent** and related methods\n\n## Kernel Ridge Regression  with Offset\n\nThe derivation of kernel ridge regression with offset is similar as KRR without offset, but with one important additional concept.\n\nFirst, the solution to ridge regression with offset is\n$$\n\\begin{aligned}\n&\\widehat{\\boldsymbol{w}}=\\left(\\tilde{\\boldsymbol{X}}^{T} \\tilde{\\boldsymbol{X}}+n \\lambda \\boldsymbol{I}\\right)^{-1} \\tilde{\\boldsymbol{X}}^{T} \\tilde{\\boldsymbol{y}} \\\\\n&\\widehat{b}=\\bar{y}-\\widehat{\\boldsymbol{w}}^{T} \\overline{\\boldsymbol{x}}\n\\end{aligned} \\tag{2.1}\n$$\nwhere\n$$\n\\tilde{\\boldsymbol{y}}=\\left[\\begin{array}{c}\n\\tilde{y}_{1} \\\\\n\\vdots \\\\\n\\tilde{y}_{n}\n\\end{array}\\right], \\quad \\tilde{y}_{i}=y_{i}-\\bar{y}, \\quad \\tilde{\\boldsymbol{X}}=\\left[\\begin{array}{c}\n\\tilde{\\boldsymbol{x}}_{1}^{T} \\\\\n\\vdots \\\\\n\\tilde{\\boldsymbol{x}}_{n}^{T}\n\\end{array}\\right], \\quad \\tilde{\\boldsymbol{x}}_{i}=\\boldsymbol{x}_{i}-\\overline{\\boldsymbol{x}}\n$$\nHere $\\overline{x}=\\sum _{i}x_{i}$, $\\overline{y}=\\sum _{i}y_{i}$. The regression func estimate is then\n$$\n\\widehat{f}(\\boldsymbol{x})=\\widehat{\\boldsymbol{w}}^{T} \\boldsymbol{x}+\\widehat{b}=\\bar{y}+\\widehat{\\boldsymbol{w}}^{T}(\\boldsymbol{x}-\\overline{\\boldsymbol{x}}) \\tag{2.2}\n$$\nTo kernelize this funciton, we can follow the exact same steps as for KRR without offset to arrive at \n$$\n\\widehat{\\boldsymbol{w}}^{T}=\\tilde{\\boldsymbol{y}}^{T}(\\tilde{\\boldsymbol{G}}+n \\lambda \\boldsymbol{I})^{-1} \\tilde{\\boldsymbol{X}} \\tag{2.3}\n$$\nthen \n$$\n\\widehat{f}(\\boldsymbol{x})=\\bar{y}+\\tilde{\\boldsymbol{y}}^{T}(\\tilde{\\boldsymbol{G}}+n \\lambda \\boldsymbol{I})^{-1} \\tilde{\\boldsymbol{g}}(\\tilde{\\boldsymbol{x}}) \\tag{2.4}\n$$\nWhere $\\tilde{x}=x-\\overline{x}$ and\n$$\n\\tilde{\\boldsymbol{G}}:=\\left[\\begin{array}{ccc}\n\\left\\langle\\tilde{\\boldsymbol{x}}_{1}, \\tilde{\\boldsymbol{x}}_{1}\\right\\rangle & \\cdots & \\left\\langle\\tilde{\\boldsymbol{x}}_{1}, \\tilde{\\boldsymbol{x}}_{n}\\right\\rangle \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\left\\langle\\tilde{\\boldsymbol{x}}_{n}, \\tilde{\\boldsymbol{x}}_{1}\\right\\rangle & \\cdots & \\left\\langle\\tilde{\\boldsymbol{x}}_{n}, \\tilde{\\boldsymbol{x}}_{n}\\right\\rangle\n\\end{array}\\right], \\quad \\tilde{\\boldsymbol{g}}(\\tilde{\\boldsymbol{x}}):=\\left[\\begin{array}{c}\n\\left\\langle\\tilde{\\boldsymbol{x}}, \\tilde{\\boldsymbol{x}}_{1}\\right\\rangle \\\\\n\\vdots \\\\\n\\left\\langle\\tilde{\\boldsymbol{x}}, \\tilde{\\boldsymbol{x}}_{n}\\right\\rangle\n\\end{array}\\right]\n$$\nBasicallly KRR w/  is like KRR w/o offset applied to the mean-centered feature space. In addition, $\\overline{y}$ is added to the predicted output.\n\n---\n\nTo see $\\tilde{G} ~\\text{and}~ \\tilde{g}(\\tilde{x})$ is kernelizable, we can expand the entries in the matrix as \n$$\n\\begin{aligned}\n\\left\\langle\\tilde{x}_{i}, \\tilde{x}_{j}\\right\\rangle &=\\left\\langle x_{i}-\\bar{x}, x_{j}-\\bar{x}\\right\\rangle \\\\\n&=\\left\\langle x_{i}, x_{j}\\right\\rangle-\\frac{1}{n} \\sum_{r=1}^{n}\\left\\langle x_{i}, x_{r}\\right\\rangle-\\frac{1}{n} \\sum_{s=1}^{n}\\left\\langle x_{s}, x_{j}\\right\\rangle+\\frac{1}{n^{2}} \\sum_{r=1}^{n} \\sum_{s=1}^{n}\\left\\langle x_{r}, x_{s}\\right\\rangle\n\\end{aligned}\\tag{2.5}\n$$\n--(calculation a bit tricky)\n\nand\n$$\n\\begin{aligned}\n\\left\\langle\\tilde{\\boldsymbol{x}}_{i}, \\tilde{\\boldsymbol{x}}\\right\\rangle &=\\left\\langle\\boldsymbol{x}_{i} -\\overline{\\boldsymbol{x}}, \\boldsymbol{x}-\\overline{\\boldsymbol{x}}\\right\\rangle \\\\\n&=\\left\\langle\\boldsymbol{x}_{i}, \\boldsymbol{x}\\right\\rangle-\\frac{1}{n} \\sum_{r}\\left\\langle\\boldsymbol{x}_{i}, \\boldsymbol{x}_{r}\\right\\rangle-\\frac{1}{n} \\sum_{s}\\left\\langle\\boldsymbol{x}, \\boldsymbol{x}_{s}\\right\\rangle+\\frac{1}{n^{2}} \\sum_{r} \\sum_{s}\\left\\langle\\boldsymbol{x}_{r}, \\boldsymbol{x}_{s}\\right\\rangle .\n\\end{aligned} \\tag{2.6}\n$$\nTherefore to kernelize ridge regression with offset, we select a kernel k and and replace $\\tilde{G}$\n\nwith $\\tilde{K}$  and $\\tilde{g}(x)$ with $\\tilde{k}(x)$.\n\nThen for $\\tilde{K}$ \n$$\nk\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{j}\\right)-\\frac{1}{n} \\sum_{r=1}^{n} k\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{r}\\right)-\\frac{1}{n} \\sum_{s=1}^{n} k\\left(\\boldsymbol{x}_{s}, \\boldsymbol{x}_{j}\\right)+\\frac{1}{n^{2}} \\sum_{r=1}^{n} \\sum_{s=1}^{n} k\\left(\\boldsymbol{x}_{r}, \\boldsymbol{x}_{s}\\right)\\tag{2.7}\n$$\nfor $\\tilde{k}(x)$\n$$\nk\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}\\right)-\\frac{1}{n} \\sum_{r} k\\left(\\boldsymbol{x}_{i}, \\boldsymbol{x}_{r}\\right)-\\frac{1}{n} \\sum_{s} k\\left(\\boldsymbol{x}, \\boldsymbol{x}_{s}\\right)+\\frac{1}{n^{2}} \\sum_{r} \\sum_{s} k\\left(\\boldsymbol{x}_{r}, \\boldsymbol{x}_{s}\\right) \\tag{2.8}\n$$\nThus, the final KRR(w/ offset) predictor is \n$$\n\\widehat{f}(\\boldsymbol{x})=\\bar{y}+\\tilde{\\boldsymbol{y}}^{T}(\\tilde{\\boldsymbol{K}}+n \\lambda \\boldsymbol{I})^{-1} \\tilde{\\boldsymbol{k}}(\\boldsymbol{x}) \\tag{2.9}\n$$\nNote  from eq. 2.4 it is very tempting to attempt to kernelize this method by replacing dot products $\\langle\\tilde{x},\\tilde{x^{\\prime}}\\rangle$ with $k(\\tilde{x},\\tilde{x}^{\\prime})$, but this is incorrect. Because we should let $\\Phi$ works for orginal $x$ \n\nfeature space.\n\nTo see it , we can introduce the notation \n$$\n\\tilde{\\Phi}(\\boldsymbol{x}):=\\Phi(\\boldsymbol{x})-\\frac{1}{n} \\sum_{i} \\Phi\\left(\\boldsymbol{x}_{i}\\right)\\tag{2.10}\n$$\n-- point is $\\Phi(\\tilde{x}) \\neq \\tilde{\\Phi}(x)$, so this approach make no sense.\n\nHere we refer to $\\tilde{\\Phi}$ as the *the centered feature map*, $\\tilde{k}(x,x^{\\prime}):=\\langle\\tilde{\\Phi}(x),\\tilde{\\Phi}(x^{\\prime})\\rangle$  as the centered kernel, and $\\tilde{K}$ as the *centered kernel matrix* associated to the training data set. \n\n","tags":["Machine learning","Kernel trick","Kernel logistic regression","feature map"],"categories":["Machine learning","Kernel trick"]},{"title":"Moment generating func&Characteristic func","url":"/2021/10/17/Moment-generating-func-Characteristic-func/","content":"\nA generating function is a clothesline on which we hang up a sequence of numbers for display ----Herbert Wlif\n\n<!-- more -->\n\n## Moment generating function\n\n### Definition of MGF\n\nwe can use moment generating function rather than PMF to define or describe a random variable.\n$$\nM(t)=\\mathbb{E}\\left[e^{t X}\\right]=\\int e^{t x} f_{X}(x) d x=\\int e^{t x} d F_{X}(x)\n$$\nWhere $X$ is a random variable of interest, $t$ is one parameter of tunction. And according to the **LOTUS** we can expand the expectation formula.\n\n----\n\nIf $M(t) \\leq \\infin$ on some interval containing the origin, then \n\n(a) $E(X)=M'(0)$    (b) $E[X^k]=M^{(k)}(0)$\n\ne.g.\n$$\n\\begin{aligned}\n&M^{\\prime}(0)=\\left.\\int x e^{t x} f_{X}(x) d x\\right|_{t=0}=\\int x f_{X}(x) d x=\\mathbb{E}[X] \\\\\n&M^{\\prime \\prime}(0)=\\left.\\int x^{2} e^{t x} f_{X}(x) d x\\right|_{t=0}=\\int x^{2} f_{X}(x) d x=\\mathbb{E}\\left[X^{2}\\right]\n\\end{aligned}\n$$\n**Notice that $M$ is function of t!!!**  and actually this structure is well-designed, everytime we take a derivative of this formula we generate a factor $x$, and we take $t =0 $  to eliminate the exponential item thus we get moment generating function.\n\n---\n\n### Property of MGF\n\n- MGF of the sum of independent random variables. \n  $$\n  M_{X+Y}(t)=\\mathbb{E}\\left[e^{t (X+Y)}\\right]=\\mathbb{E}\\left[e^{t X} e^{t Y}\\right]\n  $$\n\n- If $X,Y$ are independent then it equals to $\\mathbb{E}\\left[e^{t X} e^{t Y}\\right]=\\mathbb{E}\\left[e^{t X}]\\mathbb{E}[ e^{t Y}\\right]=M_X(t)M_Y(t)$\n\n- thus when $X_1....,X_n$ Are independently and identically distributed \n  $$\n  M_{W}(t)=\\left(M_{X}(t)\\right)^{n}\n  $$\n\nwhere $W=\\sum_{i=1}^mX_{i}$\n\n---\n\n## Characteristic function\n\nIt's very similar to the MGF but more powerful since for some random varaibles MGF doesn't exist( such as given certain $t$ MGF goes infinity). \n\n----\n\n$$\n\\begin{aligned}\n\\phi(t) &=\\mathbb{E}\\left[e^{i t X}\\right](i=\\sqrt{-1}) \\\\\n&=\\int e^{i t x} f_{X}(x) d x=\\int(\\cos t x+i \\cdot \\sin t x) f_{X}(x) d x \\\\\n&=\\mathbb{E}[\\cos t X]+i \\mathbb{E}[\\sin t X]\n\\end{aligned}\n$$\n\nProperties:\n- $\\phi(0)=\\mathbb{E}\\left[e^{i 0 X}\\right]=\\mathbb{E}[1]=1$\n- $|\\phi(t)| \\leq \\int\\left|e^{i t x}\\right| f_{X}(x) d x=\\int f_{X}(x) d x=1 .$ So $\\phi(t)$ exists while $M_{t}$ may not.\n- If $X$ and $Y$ are independent $\\phi_{X+Y}(t)=\\mathbb{E}\\left[e^{i t(X+Y)}\\right]=\\mathbb{E} e^{i t X} e^{i t Y}=\\phi_{X}(t) \\phi_{Y}(t)$\n- $Y=a X+b, a, b \\in[R]$\n\n$$\n\\phi_{Y}(t)=\\mathbb{E}\\left[e^{i t(a X+b)}\\right]=\\mathbb{E}\\left[e^{i t b} e^{i a t X}\\right]=e^{i t b} \\mathbb{E}\\left[e^{i a t X}\\right]=e^{i t b} \\phi_{X}(a t)\n$$\n\n---\n\n### Charateristic function for gaussian\n\n\n\n","tags":["Math","Probability and Random Processes"],"categories":["Math","Probability and Random Processes"]},{"title":"Transformations(functions)","url":"/2021/10/08/Transformations-functions/","content":"\n<!-- more -->\n\n## Inverse function\n\n![img](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Inverse_Function.png/220px-Inverse_Function.png)\n\nIn mathematics, an **inverse function** (or **anti-function**) is a function  that \"reverses\" another function: if the function *f* applied to an input *x* gives a result of *y*, then applying its inverse function *g* to *y* gives the result *x*, i.e., *g*(*y*) = *x* if and only if *f*(*x*) = *y*.The inverse function of *f* is also denoted as ${\\displaystyle f^{-1}}$\n\n----\n\n## Transformations (functions)\n\nLet $X$ be a random variable and $Y=g(X)$.  Given the **PDF** of $X$, find the **PDF** of **Y** .\n\n**REMARK**: The general way to find the **PDF** is to first find the **CDF** and then differentiate it to obtain the **PDF**. \n\n### Monotonous case\n\n#### 1 strictly increasing\n\nSay $g$ is **strictly increasing** and its inverse function is $h$ i.e., $h=g^{-1}$ which is also **increasing**.\n\nThe first step is to know the **CDF** of **R.V**. $Y$ and plug-in existing conditions,\n$$\nF_{Y}(y)=P(Y \\leq y)=P(h(Y) \\leq h(y))=P(X \\leq h(y))=F_{X}(h(y))\n$$\n**REMARK**:the second equation we apply $h$ function on both side thus we get $h(Y)=X$ and according to the monotone increasing of $h$ the inequality sign remains unchanged. Then with the defination of **CDF** we get $F_{X}(h(y))$\n\nThus, we can **differentiate** CDF to get PDF where chain rule will be used:\n$$\nf_{Y}(y)=\\frac{d}{d y} F_{Y}(y)=\\frac{d}{d y} F_{X}(h(y))=f_{X}(h(y)) \\frac{d h(y)}{d y}\n$$\n\n#### 2 strictly decreasing\n\nwhen it comes to decreasing case, we have minor change, see\n$$\nF_{Y}(y)=P(Y \\leq y)=P(h(Y) \\geq h(y))=1-P(X \\leq h(y))=1-F_{X}(h(y))\n$$\n\n$$\nf_{Y}(y)=\\frac{d}{d y} F_{Y}(y)=-\\frac{d}{d y} F_{X}(h(y))=-f_{X}(h(y)) \\frac{d h(y)}{d y}\n$$\n\n### No Monotonous case \n\nSay we have $Y=X^2$, $X-U(-1,1) $ \n\nobviously function is not monitonous so we can not use the conclusion aforementioned. \n\nTo solve this, firstly get the possible range of Y i.e. $Support(Y) = [0,1]$, so we assume $y \\in Y$\n$$\nF_{Y}(y)=P(Y \\leq y)=P\\left(X^{2} \\leq y\\right)=P\\left(\\left\\{x: x^{2} \\leq y\\right\\}\\right)=P(X \\in[-\\sqrt{y}, \\sqrt{y}])\n$$\nNote $X^2 \\leq y$ actually returns a set i.e. $\\set{x:x^2 \\leq y}$, \n$$\nP(X \\in[-\\sqrt{y}, \\sqrt{y}])=\\int_{-\\sqrt{y}}^{\\sqrt{y}} f_{X}(x) d x=\\int_{-\\sqrt{y}}^{\\sqrt{y}} \\frac{1}{2} d x=\\sqrt{y}\n$$\nso\n$$\nf_{Y}(y)= \\begin{cases}F_{Y}^{\\prime}(y)=\\frac{1}{2 \\sqrt{y}} & y \\in[0,1] \\\\ 0 & \\text { otherwise }\\end{cases}\n$$\n\n### Find the mapping\n\n\n\nLet $X$ and $Y$ be two random variables with PDFs $f_X$ and $f_Y$ respectively. Find a transformation $g$ such that $Y=g(X)$.\n\n**REMARK**: Since **uniform distribution** can generated any distributions , so if we can find such a function $g$ we are able to sample in the $X$ without have simulation of $Y$\n\n- Uniqueness can be guaranteed only if we assume g to be **monotone non-decreasing** or **monotone non-increasing.**\n\n--\n\n#### Example \n\n$$\n\\text { Example: } X \\sim \\mathcal{U}[0,1] \\text { and } Y \\sim \\text { Exponential }(\\lambda)\n$$\n\nFirstly, we can know $F_{X}=x$,  so $F_X(h(y))=h(y)$, \n\n\n\nSince we have known from the previous conclusion that $F_X(h(y))=F_Y(y)$ , hence we get \n$$\nh(y)=F_Y(y)=\\int_{0}^{y} \\lambda \\exp (-\\lambda t) d t=1-\\exp (-\\lambda y)\n$$\nagain $g(X)=h^-1(X)$, so to get the function $g$  we need to calculate inverse of function $h$, thus we get \n$$\ny=-\\frac{1}{\\lambda} \\log (1-h(y)): g(X)=\n\\frac{-1}{\\lambda} \\log (1-X)\n$$\n","tags":["Math","Probability and Random Processes"],"categories":["Math","Probability and Random Processes"]},{"title":"Variance&Conditional Variance","url":"/2021/10/02/EECS501-Notes2/","content":"\n<!-- more -->\n\n{% asset_img image.png %}\n\n## Variance&Conditional Variance\n\n### LECTURE 6-7 Discrete Random Variables\n\n\n\n### Variance\n\nVariance of a random variable is defined as follows:\n$$\n\\operatorname{Var}(X)=\\mathbb{E}\\left[(X-\\mathbb{E}[X])^{2}\\right]\n$$\n**REMARK:** $E(X)$ is one way to summarize the PMF $P_X$, but it connot capture **randomness/uncertainty** thus we need variance.\n\n#### Alternative expresion for variance\n\n$$\n\\begin{aligned}\n\\operatorname{Var}(X) &=\\mathbb{E}\\left[(X-\\mathbb{E}[X])^{2}\\right] \\\\\n&=\\mathbb{E}\\left[X^{2}-2 X \\mathbb{E}[X]+\\mathbb{E}[X]^{2}\\right] \\\\\n&=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}[2 X \\cdot \\mathbb{E}[X]]+\\mathbb{E}\\left[(\\mathbb{E}[X])^{2}\\right] \\\\\n&=\\mathbb{E}\\left[X^{2}\\right]-2 \\mathbb{E}[X] \\mathbb{E}[X]+(\\mathbb{E}[X])^{2} \\\\\n&=\\mathbb{E}\\left[X^{2}\\right]-(\\mathbb{E}[X])^{2} \\\\\n&=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}^{2}[X]\n\\end{aligned}\n$$\n\nNote that $Var(X)\\geq 0$ and it equals 0 if and only if $X$ is a **constant function** \n\n### Conditional variance\n\nconditional variance is analogous to conditional expectation. Let $A$ be some event and $X,Y$ be some random variables.\n\n1. $\\operatorname{Var}(X \\mid A)=\\mathbb{E}\\left[(X-\\mathbb{E}[X \\mid A])^{2} \\mid A\\right]=\\sum_{x}(x-\\mathbb{E}[X \\mid A])^{2} \\cdot P_{X \\mid A}(x)$\n\n   $X|A$ is random variable of $X$\n\n   Alternatively, $\\operatorname{Var}(X \\mid A)=\\mathbb{E}\\left[X^{2} \\mid A\\right]-\\mathbb{E}^{2}[X \\mid A]$\n\n   Similarly, $\\operatorname{Var}(X \\mid Y=y)=\\operatorname{Var}(X \\mid\\{Y=y\\})=\\mathbb{E}\\left[(X-\\mathbb{E}[X \\mid Y=y])^{2} \\mid Y=y\\right]$\n\n2. $\\operatorname{Var}(X \\mid Y)(y)=\\operatorname{Var}(X \\mid Y=y)$\n\n   $X|Y$ is a random variable of $Y$ thus a function of $Y$ \n\n   $\\operatorname{Var}(X \\mid Y)=\\mathbb{E}\\left[X^{2} \\mid Y\\right]-\\mathbb{E}^{2}[X \\mid Y]$\n\n### Law of total variance ***\n\n$$\n\\operatorname{Var}(X)=\\mathbb{E}[\\operatorname{Var}(X \\mid Y)]+\\operatorname{Var}(\\mathbb{E}[X \\mid Y])\n$$\n\n- why we need the second item?\n\n  consider $Var(X|X)$ , it is a function of $X$ , so $Var(X|X)_(x)=Var(X|X=x)=Var(X=x)=0$, for any $x$ the function give the zero output, so we say $Var(X|X)=0$ is a function of constant, the $E[Var(X)]=0$] obviously, if we don't have the second item the equation above will not make sense.\n\n  ---\n\n  **PROVE**\n  $$\n  \\begin{aligned}\n  \\mathbb{E}[\\operatorname{Var}(X \\mid Y)] &=\\mathbb{E}\\left[\\mathbb{E}\\left[X^{2} \\mid Y\\right]-\\mathbb{E}^{2}[X \\mid Y]\\right] \\\\\n  &=\\mathbb{E}\\left[\\mathbb{E}\\left[X^{2} \\mid Y\\right]\\right]-\\mathbb{E}\\left[\\mathbb{E}^{2}[X \\mid Y]\\right] \\\\\n  &=\\mathbb{E}\\left[X^{2}\\right]-\\left(\\operatorname{Var}(Z)+\\mathbb{E}^{2}[Z]\\right) \\\\\n  &=\\mathbb{E}\\left[X^{2}\\right]-(\\mathbb{E}[\\mathbb{E}[X \\mid Y]])^{2}-\\operatorname{Var}(Z) \\\\\n  &=\\mathbb{E}\\left[X^{2}\\right]-(\\mathbb{E}[X])^{2}-\\operatorname{Var}(Z)\n  \\end{aligned}\n  $$\n  Thus, $\\mathbb{E}[\\operatorname{Var}(X \\mid Y)]+\\operatorname{Var}(\\mathbb{E}[X \\mid Y])=\\operatorname{Var}(X)$\n\n---\n\n- The **first step** we just expand the variance and **the second** we use the Linearity of expectation.\n- Then to be concise, let $Z$ denote $X|Y$,  the first item **in third step** become $E[X^2]$ because the property of **smoothing**.\n- using smoothing again we get fourth step\n- then let $Var(X)$ substitute the first two items in **step 5**, we then get all we want. \n\n--------\n\n### Small practice\n\n- We have two bins {1; 2} and each bin has three types of balls {0; 2; 4}: A bin is\n\nrandomly selected  first and then a ball is drawn from the bin. The fraction of each\n\ntype of balls in each bin is shown in the following table.\n\n| -    | 0    | 2    | 4    |\n| ---- | ---- | ---- | ---- |\n| Bin1 | 0.6  | 0.3  | 0.1  |\n| Bin2 | 0.1  | 0.3  | 0.6  |\n\nLet X denote the type of the ball selected. Calculate Var (X)\n\n-----\n\n**analysis**: we can solve it by calculating the pmf of $X$, but we should use the marginal distribution to calculate it from the distribution of joint $X,Y$, it will not be trivial since this is just a discrete case. \n\nbut the purpose of this small practice is to use **LOTV**, thus string all the concept together. \n\n---\n\n**Solution**:\n\nSo let us first expand $Var(X)$ by **LOTV**:\n$$\nVar(X)=\\mathbb{E}[\\operatorname{Var}(X \\mid Y)]+\\operatorname{Var}(\\mathbb{E}[X \\mid Y]) \\tag{1}\n$$\nNote that $E[X|Y]$  and $Var[X|Y]$ are both **function of Y** thus both **random variables**. and to be convise we denote them $Z1~~Z2$ respectively. \n$$\nVar(X)=\\mathbb{E}[\\operatorname{Z2}]+\\operatorname{Var}(\\mathbb{E}[Z1]) \\tag{2}\n$$\nWhen calculate the **expectation and variance** of a random variable we should know its all valid **real value and correspondent pmf**. \n\n---\n\nfor $Z1$, since its function of Y and Y is a discrete  R.V.  with only two valid value hence we can get two \n\n**conditional expectation**\n$$\n\\begin{aligned}\n&\\{Z 1=1\\}=\\{E[X \\mid Y=1]\\}=\\sum_{x \\in v a l(x)} x * p(x \\mid y=1)=1 \\\\\n&\\ldots \\quad p(Z 1=1)=\\sum_{x} p(x \\mid y=1)=p(Y=1) \\\\\n&\\{Z 1=2\\}=\\{E[X \\mid Y=2]\\}=\\sum_{x \\in v a l(x)} x * p(x \\mid y=2)=3 \\\\\n&\\cdots \\quad p(Z 1=2)=\\sum_{x} p(x \\mid y=2)=p(Y=2)\n\\end{aligned}\n$$\n**Note** $X|Y=1$ is function of X, when we calculate its expectation, actually we are just calculating a conditional expectation (**which just change the pmf to conditional pmf given conditions**) .\n\nsimilarly, we have **conditional variance**\n\n$$\n\\begin{gathered}\n\\{Z 2=1\\}=\\operatorname{Var}[X \\mid Y=1]=\\sum_{x}(x-E[X \\mid Y=1])^{2} p(x \\mid y=1) \\\\\n=(0-1)^{2} * 0.6+(2-1)^{2} * 0.3+(4-1)^{2} * 0.1=1.8 \\\\\n\\cdots \\quad p(Z 2=1)=P(Y=1)=1 / 2 \\\\\n\\{Z 2=2\\}=\\operatorname{Var}[X \\mid Y=2]=\\sum_{x}(x-E[X \\mid Y=2])^{2} p(x \\mid y=1) \\\\\n=(0-3)^{2} * 0.6+(2-3)^{2} * 0.3+(4-3)^{2} * 0.1=1.8 \\\\\n \\cdots \\quad p(Z 2=2)=P(Y=2)=1 / 2\n\\end{gathered}\n$$\n\nSo we have get all the information need to calculate the **expectation** of R.V. $Z2$ and **variance** of R.V. $Z1$. \n\nthe former is $E[Z2]=\\sum_{z_{2}}z_{2}*P(z_{2})=1.8$ and the latter is $\\operatorname{Var}[Z 1]=\\sum_{z_{1}}\\left(z_{1}-E[Z 1]\\right)^{2} * p\\left(z_{1}\\right)=1$ where $E(Z1)=2$, so we get the answer **2.8**\n\n\n\n**REMARK**:  when using **LOTV**, we should firstly specify  **two R.Vs** and calculating all their **real value-pdf** when calculate their value, note that we are calculate the **conditional expectation** or conditional variance of another random variable i.e. the $X$ in $X|Y$ which result a real value. and the pmf\n","tags":["Math","Probability and Random Processes"],"categories":["Math","Probability and Random Processes"]},{"title":"Conditional PMF&Expectation","url":"/2021/10/01/EECS501-Notes1/","content":"\n<!-- more -->\n\n{% asset_img image.png %}\n\n\n## Conditional PMF&Expectation\n### LECTURE 6-7 Discrete Random Variables\n\n\nFor the **conditional PMF** we have\n$$\nP_{X \\mid Y}(x \\mid y)=P(\\{X=x\\} \\mid Y=y)=\\frac{P(\\{X=x\\} \\cap\\{Y=y\\})}{P(\\{Y=y\\})}=\\frac{P_{X Y}(x y)}{P_{Y}(y)}\n$$\nAs for the **conditional Expectation**, we first talk about the case \n$$\n\\mathbb{E}[X \\mid A]=\\sum_{x} x P_{X \\mid A}(x)\n$$\n$X|A$ can be regarded as a **R.V. conditioned on event A**(a bunch of sets from sample space), the difference between $E[X] ~and~E[X|A]$  is the latter changed the **PMF $P_X~to~P_{X|A}$** when calculating.\n\nThen we elaborate on the case\n$$\ng(y)=\\mathbb{E}[X \\mid Y](y \\mid)=\\mathbb{E}[X \\mid Y=y]\n$$\nwhere **event A** is substituted by the **R.V.** $Y$ , note that in this circumstance the expectation should be a **function of Y** which means **function of function** mapping the event $\\set{Y=y_i}$ to real numbers, and hence it is also a R.V.\n\n\n\n### Independence of a R.V. from a event\n\n####  independence of a R.V. from a event\n\n$$\nP_{X \\mid A}(x)=P_{X}(x) \\quad \\forall x\n$$\n\n####  independence of two R.V. \n\n$$\n\\begin{gathered}\nP_{X Y}(x, y)=P_{X}(x) P_{Y}(y) \\quad \\forall x, y \\\\\n\\Rightarrow P_{X \\mid Y}(x \\mid y)=P_{X}(x)\n\\end{gathered}\n$$\n\n#### independence of several R.V. \n\n$$\nP_{X Y Z}(x, y, z)=P_{X}(x) P_{Y}(y) P_{Z}(z), \\forall x, y, z\n$$\n\nNote that it seems different form the **definition** of **independent of three events**, but actually they are **essentially equivalent.** \n\nReason is we can derive the following form in three events just by applying the marginal distribution. \n$$\n\\begin{aligned}\nP_{X Y}(x, y) &=\\sum_{z} P_{X Y}(x, y, z) \\\\\n&=\\sum_{z} P_{X}(x) P_{Y}(y) P_{Z}(z)=P_{X}(x) P_{Y}(y)\n\\end{aligned}\n$$\n\n\n### LOTE: Law of total expectation\n\nEnsure that we have the probability space: $(\\Omega, \\mathcal{F}, P)$ with $B_1,B_2...B_n$ be a **partition** of the $\\Omega$. Then let $X$ be a R.V. on $\\Omega$ with PMF $P_X$, Then we can have \n$$\n\\mathbb{E}[X]=\\sum_{i=1}^{n} P\\left(B_{i}\\right) \\mathbb{E}\\left[X \\mid B_{i}\\right]\n$$\n\n### Some important property of expectation of R.V.\n\n#### 1. Smoothing/law of iterated expectation $\\mathbb{E}[\\mathbb{E}[Y \\mid X]]=\\mathbb{E}[Y]$\n\nWhen we are asked to calculate $E[Y]$ but we find it a little bit difficult, we can try to **calculate left hand side equation instead**\n\n**emphasis again**: $E[Y|X]$ is function of R.V. $X$ , so when calculating the $E[E[Y|X]]$, we need to know all the potential value of R.V. $Z=g(X)$ also the corresponding probability value of $X$\n\n e.g. $\\mathbb{E}[Y \\mid X=1]=\\sum_{y} x P_{Y \\mid X}(y \\mid 1)$ is one of the value of R.V. and its corresponding pmf is $P(X=1)$\n\n#### 2. $\\mathbb{E}[h(X) \\mid X]=h(X)$\n\nwe can just remember this equation by: when we know $X$ then $h(X)$ become real value and the expectation of constant is itself.\n\n#### 3. Substitution $\\mathbb{E}[g(X, Y) \\mid X=x] \\mid=\\mathbb{E}[g(x, Y) \\mid X=x]$\n\n**PROVE：**\n$$\n\\begin{gathered}\n\\mathbb{E}[Z \\mid X=x]=\\sum_{y} \\mathbb{E}[Z \\mid X=x, Y=y] P(Y=y \\mid X=x) \\\\\n=\\sum_{y} g(x, y) P(Y=y \\mid X=x)\\\\ \\text{[LOTE]} \\\\\n\n\\mathbb{E}\\left[Z_{x} \\mid X=x\\right]=\\sum_{y} g(x, y) P(Y=y \\mid X=x)\\\\\n\\text{[LOTUS]}\n\\end{gathered}\n$$\n#### 4. $\\mathbb{E}[g(X) Y \\mid X]=g(X) \\mathbb{E}[Y \\mid X]$\n\n\n\n#### 5. Towering $\\mathbb{E}[\\mathbb{E}[X \\mid Y, Z] \\mid Z]=\\mathbb{E}[X \\mid Z]$\n\nA little trivial, but just remember two things:\n\n1. $\\mathbb{E}_{X \\mid Y, Z}[X \\mid Y, Z]$ is a function of two random variables Y and Z\n\n2. $\\mathbb{E}_{Y \\mid Z}\\left[\\mathbb{E}_{X \\mid Y, Z}[X \\mid Y, Z] \\mid Z\\right]=\\mathbb{E}_{Y \\mid Z}[g(Y, Z) \\mid Z]$ is a function of Z\n\n---\n\n**My intuition: when we calculate the expectation of function of multiple r.v. it can work as flatten which have the same sense when we reduce dimention in matrix** \n\n","tags":["Math","Probability and Random Processes","Conditional PMF&Expectation"],"categories":["Math","Probability and Random Processes"]},{"title":"《雾中》","url":"/2021/08/07/雾中/","content":"\n<img src=\"/images/fog.jpg\" width=\"500\">\n\n## 雾中\n\n在雾中散步真是奇妙！\n\n一木一石都很孤独，\n\n没有一棵树看到别棵树，\n\n棵棵都很孤独。\n\n当我生活得开朗之时，\n\n我在世上有很多友人；\n\n如今，\n\n由于大雾弥漫，\n\n再也看不到任何人。\n\n确实，\n\n不认识黑暗的人，\n\n决不能称为明智之士，\n\n难摆脱的黑暗悄悄地\n\n把他跟一切人隔离。\n\n在雾中散步真是奇妙！\n\n人生就是孑然孤独的样子。\n\n独处。\n\n没有一个人了解别人，\n\n人人都很孤独。\n\n### Im Nebel\n\nSeltsam, im Nebel zu wandern!\nEinsam ist jeder Busch und Stein,\nKein Baum sieht den andern,\nJeder ist allein.\n\nVoll von Freunden war mir die Welt,\nAls noch mein Leben licht war;\nNun, da der Nebel fällt,\nIst keiner mehr sichtbar.\n\nWahrlich, keiner ist weise,\nDer nicht das Dunkel kennt,\nDas unentrinnbar und leise\nVon allen ihn trennt.\n\nSeltsam, im Nebel zu wandern!\nLeben ist Einsamsein.\nKein Mensch kennt den andern,\nJeder ist allein.\n\n---\n\n{% meting \"1859874\" \"netease\" \"song\" \"autoplay\"%}\n\n\n\n","tags":["Life","Poem"],"categories":["Life","Poem"]},{"title":"终点和意义","url":"/2021/05/22/终点和意义/","content":"\n<!-- more -->\n\n{% meting \"5265370\" \"netease\" \"song\" %}\n\n意义困扰了我很多年，第一次意识到人生终点那会，心里真的很害怕，会恐惧也抗拒，那种凝视虚空的感觉让我感受到孤独无助。我甚至会在脑海里想象至亲离世时手握着他们苍白的手亦或是自己年迈衰老濒死之际自己的孩子在病床前守候的场景，就像电影《返老还童》开头渲染那一般。高考前的那段时间以及大学的前几年对终点的恐惧都让我十分挣扎尤其是在独自一人的难眠之夜。\n\n\n\n我觉得这是一件很残酷的事情，因为无论我在人生跑道上漫步或是奔跑领先或是落后，最后都有那么一个终点等着我，到那时无论心中还有多大的执念我也只能放手。可我想一直跑我并不想结束我也害怕结束，甚至贪婪的我还想和我的朋友亲人们一直在一起。但是终点就在那并且丝毫不受任何主观的影响甚至不存在客观上的改变。\n\n\n\n就像美剧《True Detective》中Rust的那段话:“我认为人类的意识是进化过程中的一个可悲的错误，这让我们变得太有自我意识了。自然从自身中抽离出一部分又化为自然，但从自然法则来说我们是不该存在的生物，我们被“拥有自我”这一幻觉给奴役了。因为感官体验和感觉相结合，被设定成让我们相信我们每个人都是某个人，可事实上我们谁都不是。我认为对于所有物种来说，最崇高的事情就是拒绝被设定、停止繁殖、手牵手走向灭亡。”\n\n\n\n个体拥有强烈的自我意识的确是荒谬的，这种强烈的自我意识让我很难过的洒脱，也很难积极投入到现实中，我是多想像《牛氓》中描述的那样“无论我活着，还是死去，我都是一只牛氓，快乐地飞来飞去。”就那么漫无目的的飞来飞去多好啊！\n\n\n\n对终点的思考似乎并不像是突然在我脑海中蹦出，我想这一切应该是归结于那时候自身拒绝社交把自己封闭在自己狭小的舒适圈中，因为曾经在多次目睹人性的恶毒后，精疲力尽，开始对人群和集体有了莫名的恐惧，我主动把自己边缘化了，把自己从集体中抽离出来。也因此我对一系列社会活动不再上心，于是乎那几年感觉自己浑浑噩噩的,靠游戏和动漫麻醉自己。意义的缺失让我感到迷茫，对于大家热衷的GPA，科研，竞赛都让我提不起兴趣来。我只是按部就班完成已经变成习惯的日常。\n\n\n\n那段时间观察身边的人成为了唯一的乐趣，人群中有为了填补心中的自卑感甘愿被虚荣奴役的，也有为了蝇头小利绞尽脑汁去利用别人并为此沾沾自喜的，还有笑里藏刀极尽恶毒的虚伪之人......当然也不乏真诚正直的，善良无所求真心帮助鼓励他人的。但是无论如何，大家好像都很忙碌，似乎身边的人都没有去在意既定的终点。\n\n\n\n一时间感觉自己就像是一个在人来人往的十字街口的幽灵，站在岔路中央，来来往往的行人从我身上穿过，漫无目的游荡的却似乎只有我一个。我想我是我迷失了,在这荒诞的人生中寻找意义就像是缘木求鱼。\n\n\n\n直到经历了很多事情后我才明白，就像臧克家的那句“人生永远追逐幻光，谁把幻光看作幻光，谁便沉入无边苦海” ，也许意义从来不在于意义本身。\n\n\n\n现实的拷打是我摆脱这个桎梏的重大契机，因为我从来不是一个可以从抽象概念之中建立起更高层认知的人，本能的怀疑让我无法专注于其中。本质上，我是那种需要空间和具象的人，我更擅长从实例中去抽象解构概念然后再去构建新的概念。也因此注定了现实和实践才是我摆脱这一牢笼的关键。\n\n\n\n还记得那段时间接连的情感上的挫败，朋友的利用和背叛以及直面残酷的生死离别让我感受到巨大的痛苦。消极情绪将我吞噬，那段时间十分嗜睡，因为梦中的世界还没变的一塌糊涂。可是一旦梦又醒了，一切还是照旧。\n\n\n\n幸运的是，假期里我收到了朋友的一次旅行邀约。是去新西兰，南半球的一个小岛国，也是在那里我见到了更大的世界，体验到了更多的新奇之物。\n\n\n\n那时候，出去看一看的想法开始萌生，也是从那时候我才真正开始对人生开始了模糊的规划，就像是模电中的正反馈。之后一切都开始悄然改变，不断地突破不断地和新的人接触，我体验到了更多，觉得充实。开始慢慢的不去思考人生的意义，也不再去畏惧终点。我找到了自己的路，并且只想坚定的走下去。\n\n\n\n叔本华说生命是一团欲望，欲望得不到满足就痛苦，满足便无聊，人生在痛苦和无聊之间摇摆。而我的欲望仅仅是不断去体验去突破人生的边际罢了。\n\n{% asset_img Newzealand.jpeg %}\n\n","tags":["Life","Meaning"],"categories":["Life","Record"]},{"title":"Interpretable Machine Learning(LIME-1)","url":"/2021/04/15/Interpretable Machine Learning/","content":"\n## 关于LIME\n因为研究需要，得弄懂kernel SHAP所以先得弄明白LIME，不想这东西还挺有意思的，该算法发表在2016的KDD上，先挂个介绍视频吧。\n\n{% youtube hUnRCxnydCc %}\n视频简单形象介绍了LIME以及该算法的motivation和intuition. 总结一下，我们可以用LIME去1) 在几个旗鼓相当（性能相似）的模型中做选择。2）去鉴别不值得信任的模型并改善。3）从模型中得到新的发现灵感。\n\n具体一点，\n1）的应用主要是在满足metric需要的模型之间找到更适合需求的模型，比如有的模型虽然perform well但是解释性一团糟，又比如有的语言模型涉嫌种族歧视……\n\n2）有一些模型perform beyond expectation，有很大嫌疑发生了data leakage（我就被这个坑惨了），比如说用来鉴别学生属于哪个班级，模型将学生ID作为特征，而由ID可直接推出学生班级。又比如图像领域，识别北极熊和棕熊，模型将雪地背景作为判别image 是否为北极熊的重要特征。这些模型虽然表现的很好但是却毫无意义（本质为过拟合），在部署上线后会变得一塌糊涂。\n\n3）这方面应用就比较灵活了，可以用于异常检测，也可以用于特征选择或者构建新的powerful feature....\n\n## LIME算法\n### IDEA\nLIME（Local Interpretable Model-Agnostic Explanations )属于局部代理模型，是一种可解释的模型用于解释黑盒机器模型对单个实例（individual）的预测。它的想法非常直觉，首先我们仅保留训练好的黑盒模型，然后扰动数据生成新的样本，通过黑盒模型得到这些样本的预测值作为LIME explainer的label，训练LIME explainer，由于explainer对比原来的黑盒模型更加简单，我们可以通过它作为原始黑盒模型的代理对感兴趣的样本点进行解释和分析。\n\n实际上，explainer可以是任何模型，但是因为复杂度的因素，Lasso（linear regression with L1）和decision tree通常被选作explainer.\n\n### Mathematics \n\n数学上，带有模型复杂度（可解释性）正则项限制的局部代理模型\n$$\n\\operatorname{explanation}(x)=\\arg \\min _{g \\in G} L\\left(f, g, \\pi_{x}\\right)+\\Omega(g)\n$$\n其中f函数代表待解释的black-box model, g函数则是在G函数空间中的一个解释性模型，$π_x$代表感兴趣样本x的邻样本范围的大小。\n\n\n\n显然，$π_x$如果越大，则有越多的远离interest point的实例被用于构建local surrogate explainer，可能会引入一些新的解释。其次关于正则项$\\Omega(g)$，我个人的理解是G空间中会有很多在损失函数上表现相当的函数，我们要从中选取那些复杂度低，解释性好的。具体的，该项可以用于heterogeneous models之间的选择，比如决策树和线性模型，也可以用于homogeneous models之间的选择，不同特征数量的线性模型或者不同深度不同叶子节点数目的决策树等....\n\n\n\n但是这里需要注意的是，在实际操作中，我们只对损失函数项进行优化，复杂度的正则项是通过我们预先限制模型的复杂度来得到的。\n\n### Recipe for raining local surrogate models\n\n其算法执行的流程大致如下:\n\n\n1） 选择感兴趣的实例（经由黑盒模型预测的某个实例）\n\n2）扰动数据集（采样）得到新的样本，并输入到黑盒模型中得到其预测值作为其标签。\n\n3）对这些新的样本根据与感兴趣实例的接近程度（类似特征向量的欧氏距离）来进行赋权。\n\n4）基于新的样本训练可解释模型\n\n5）通过可解释模型解释感兴趣的实例\n\n\n\n\n\n","tags":["Machine learning","Interpretable Machine Learning","LIME"],"categories":["Machine learning","Interpretable Machine Learning"]},{"title":"Lloyd-Max Quantizer","url":"/2021/04/05/Lloyd-Max Quantizer/","content":"# PDF资料\n{% pdf ./Max-Floyd.pdf %}\n# 作业要求\n>参考 Max-Floyd.pdf 中的example 2, 将$p(x)$修改成高斯分布$N(0,1)$\n\n# 代码实现\n```python\nimport scipy.stats as stats\nfrom scipy.integrate import quad\nimport math\ny1=0.3;y2=0.8;max_iterations=500;precision=1e-9\n# p=1\n# p=stats.norm.pdf(x,0,1)\nnum_func=lambda x: x*stats.norm.pdf(x,0,1)\nden_func=lambda x: stats.norm.pdf(x,0,1)\nfor i in range(max_iterations):\n    b1=(y1+y2)/2\n    Num1,Nerr1=quad(num_func,0,b1)\n    Den1,Derr1=quad(den_func,0,b1) \n    y1=Num1/Den1\n    Num2,Nerr2=quad(num_func,b1,1)\n    Den2,Derr2=quad(den_func,b1,1) \n    tmp=y2\n    y2=Num2/Den2\n    if abs(y2-tmp)<precision:\n        print('iterations:',i)\n        break\nprint('y1:',y1,'y2:',y2,'b1:',b1)\n```\n\n# 深入思考\n未完待写..","tags":["Machine learning","Python","Optimisation"],"categories":["Machine learning"]}]